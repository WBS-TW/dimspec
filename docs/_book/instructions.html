<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Instructions | A User Guide for the NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Tool Set</title>
  <meta name="description" content="This is the User Guide distributed alongside the R Project containing the toolset supporting the “Database Infrastructure for Mass Spectrometry (DIMSpec)” project." />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="Instructions | A User Guide for the NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Tool Set" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/assets/NIST-Logo-Brand-White.svg" />
  <meta property="og:description" content="This is the User Guide distributed alongside the R Project containing the toolset supporting the “Database Infrastructure for Mass Spectrometry (DIMSpec)” project." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Instructions | A User Guide for the NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Tool Set" />
  
  <meta name="twitter:description" content="This is the User Guide distributed alongside the R Project containing the toolset supporting the “Database Infrastructure for Mass Spectrometry (DIMSpec)” project." />
  <meta name="twitter:image" content="/assets/NIST-Logo-Brand-White.svg" />

<meta name="author" content="Jared M. Ragland and Benjamin J. Place" />


<meta name="date" content="2022-09-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro-start.html"/>
<link rel="next" href="technical-details.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<a href="https://www.nist.gov"><img id="nist-logo" src="assets/NIST-Logo-Brand-White.svg"></img></a>
<p id="book-title">DIMSpec User Guide</p>

<li class="divider"></li>
<li><a href="index.html#preface">Preface<span></span></a></li>
<li><a href="intro-start.html#intro-start">Introduction<span></span></a>
<ul>
<li><a href="intro-start.html#intro-contributors">Contributors<span></span></a></li>
<li><a href="intro-start.html#intro-contributing">Contributing<span></span></a></li>
<li><a href="intro-start.html#intro-about">About this Book<span></span></a></li>
</ul></li>
<li><a href="instructions.html#instructions">Instructions<span></span></a>
<ul>
<li><a href="instructions.html#installation">Installation<span></span></a>
<ul>
<li><a href="instructions.html#system-requirements">System Requirements<span></span></a></li>
<li><a href="instructions.html#quick-start-guide">Quick Start Guide<span></span></a></li>
</ul></li>
<li><a href="instructions.html#project-directory">Project Directory<span></span></a></li>
<li><a href="instructions.html#project-set-up">Project Set Up<span></span></a>
<ul>
<li><a href="instructions.html#step-1---global-compute-environment-settings">Step 1 - Global compute environment settings<span></span></a></li>
<li><a href="instructions.html#step-2---customizing-r-session-settings-in-the-env_r.r-file">Step 2 - Customizing R session settings in the “env_R.R” file<span></span></a></li>
<li><a href="instructions.html#step-3---customizing-logger-settings-in-the-env_logger.r-file">Step 3 - Customizing logger settings in the “env_logger.R” file<span></span></a></li>
</ul></li>
<li><a href="instructions.html#using-dimspec">Using DIMSpec<span></span></a>
<ul>
<li><a href="instructions.html#database-connections">Database Connections<span></span></a></li>
<li><a href="instructions.html#using-a-database-connection-in-an-r-session">Using a Database Connection in an R Session<span></span></a></li>
<li><a href="instructions.html#inspecting-database-properties">Inspecting Database Properties<span></span></a></li>
<li><a href="instructions.html#using-the-api">Using the Application Programming Interface (API)<span></span></a></li>
<li><a href="instructions.html#using-rdkit">Using rdkit<span></span></a></li>
<li><a href="instructions.html#logging">Logging<span></span></a></li>
<li><a href="instructions.html#using-shiny-applications">Using Shiny Applications<span></span></a></li>
<li><a href="instructions.html#importing-data">Importing Data<span></span></a></li>
<li><a href="instructions.html#ending-your-session">Ending Your Session<span></span></a></li>
<li><a href="instructions.html#updating-the-schema">Updating the Schema<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="technical-details.html#technical-details">Technical Details<span></span></a>
<ul>
<li><a href="technical-details.html#database-schema">Database Schema<span></span></a>
<ul>
<li><a href="technical-details.html#sql-nodes">SQL Nodes<span></span></a></li>
</ul></li>
<li><a href="technical-details.html#populating-data-at-build">Populating Data at Build<span></span></a></li>
<li><a href="technical-details.html#compute-environments">Compute Environments<span></span></a></li>
<li><a href="technical-details.html#shiny-applications">Shiny Applications<span></span></a>
<ul>
<li><a href="technical-details.html#app-table-explorer">Table Explorer<span></span></a></li>
<li><a href="technical-details.html#app-msmatch">Mass Spectral Match (MSMatch)<span></span></a></li>
<li><a href="technical-details.html#app-mscq">Mass Spectral Quality Control (MSQC)<span></span></a></li>
</ul></li>
<li><a href="technical-details.html#logger">Logger<span></span></a></li>
<li><a href="technical-details.html#plumber">Plumber<span></span></a></li>
<li><a href="technical-details.html#python">Python<span></span></a></li>
<li><a href="technical-details.html#importing-data-td">Importing Data<span></span></a></li>
<li><a href="technical-details.html#future-development">Future Development<span></span></a></li>
</ul></li>
<li><a href="conclusions.html#conclusions">Conclusions<span></span></a></li>
<li><a href="table-explorer-home.html#table-explorer-home">App - Table Explorer<span></span></a>
<ul>
<li><a href="table-explorer-home.html#table-viewer">Table Viewer<span></span></a></li>
<li><a href="table-explorer-home.html#entity-relationship-diagram">Entity Relationship Diagram<span></span></a></li>
</ul></li>
<li><a href="msmatch-home.html#msmatch-home">App - Mass Spectral Match (MSMatch)<span></span></a>
<ul>
<li><a href="msmatch-home.html#msmatch-intro">Introduction<span></span></a></li>
<li><a href="msmatch-home.html#msmatch-instructions">Instructions<span></span></a>
<ul>
<li><a href="msmatch-home.html#msmatch-file-format">Input File Format Requirements<span></span></a></li>
<li><a href="msmatch-home.html#msmatch-launching-msmatch">Launching MSMatch<span></span></a></li>
<li><a href="msmatch-home.html#msmatch-using-msmatch">Using MSMatch<span></span></a></li>
</ul></li>
<li><a href="msmatch-home.html#msmatch-technical-details">Technical Details<span></span></a>
<ul>
<li><a href="msmatch-home.html#msmatch-search-object">Mass Spectral Search Object<span></span></a></li>
<li><a href="msmatch-home.html#msmatch-algorithms">Compound and Fragment Match Algorithms<span></span></a></li>
<li><a href="msmatch-home.html#msmatch-application-settings">Application Settings<span></span></a></li>
<li><a href="msmatch-home.html#msmatch-future">Future Development<span></span></a></li>
</ul></li>
<li><a href="msmatch-home.html#msmatch-conclusions">Conclusions<span></span></a></li>
</ul></li>
<li><a href="mass-spectral-quality-control-msqc-a-shiny-application.html#mass-spectral-quality-control-msqc-a-shiny-application">Mass Spectral Quality Control (MSQC, a Shiny application)<span></span></a></li>
<li><a href="references.html#references">References<span></span></a></li>
<li><a href="appendix-function-reference.html#appendix-function-reference">Appendix - Function Reference<span></span></a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A User Guide for the NIST Database Infrastructure for Mass Spectrometry (DIMSpec) Tool Set</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="instructions" class="section level1 unnumbered hasAnchor">
<h1>Instructions<a href="instructions.html#instructions" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="installation" class="section level2 unnumbered hasAnchor">
<h2>Installation<a href="instructions.html#installation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>At the moment, this tool set is only available outside of NIST through GitHub (the preference, either by fork, clone, or download) or directly from one of this book’s authors. For now, this tool set includes the NIST PFAS Spectral Library as an R project which can be opened directly in the <a href="https://www.rstudio.com/">RStudio Integrated Development Environment (IDE)</a><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> which may be downloaded and installed free of charge if not already installed on a target system. Initial set up does require an internet connection to download software installers and dependencies; on a system which does not contain any software components this can take a considerable amount of time.</p>
<div id="system-requirements" class="section level3 unnumbered hasAnchor">
<h3>System Requirements<a href="instructions.html#system-requirements" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>DIMSpec has been tested on both Windows 10 and Ubuntu 20.0.4.3 LTS 64-bit<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> platforms and should run on any system able to install R, Python, SQLite3, and a web browser, though installation details may vary for other operating systems. Follow the instructions for each requirement on the target operating system.</p>
<p><strong>[REQUIRED]</strong> <strong>R 4.1+</strong> (<a href="https://cran.r-project.org/">download</a>) and many packages are required (R Core Team, 2021; various); necessary packages will be installed when the compliance file is sourced, which may take some time when the project is first installed. The RStudio IDE (<a href="https://www.rstudio.com/products/rstudio/download/#download">download</a>; RStudio Team, 2015) is highly recommended for ease of use as this project is distributed as a R project.</p>
<p><strong>[STRONGLY RECOMMENDED]</strong> <strong>SQLite3</strong> (<a href="https://www.sqlite.com/download.html">download</a>) and its command line interface (CLI; <a href="https://www.sqlite.org/cli.html">download</a>) provide the database engine in structured query language (SQL) and are not technically required as the build can be accomplished purely through R, but it highly recommended to streamline the process and manipulate the database. A lightweight database interface such as <a href="https://dbeaver.com/download/lite/">DBeaver Lite</a> is also suggested for interacting with the database in a classical sense. <strong>Git</strong> (<a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">install instructions</a>) is a repository manager which will make it much easier to install and update the project without downloads. The sqlite3 CLI and git executables must be available via PATH.</p>
<p><strong>[RECOMMENDED]</strong> For chemical informatics support, both <strong>Python 3.9+</strong> and the <strong>rdkit</strong> library are required for certain operations supporting display and calculations, primarily generation of machine-readable identifiers (e.g. InChI, InChIKey, SMILES, etc) but the full capabilities of rdkit are available (see the <a href="https://www.rdkit.org/docs/index.html">RDKit documentation</a> for details); these are turned on by default but are completely optional. An <strong>anaconda</strong> or <strong>miniconda</strong> installation is required. Python integration is not required for spinning up the basic database infrastructure. Users may need to add the conda executable to their PATH and, if conda is already installed, should pay close attention to the Python section of Technical Details. If these are not available, R will install miniconda (this requires user confirmation at the console) and create the necessary environment as part of automated setup during the compliance script. (Another option for chemical informatics is to use the Java-based R package rcdk instead; users will need to install the Java framework prior to installing rcdk (see <a href="https://cimentadaj.github.io/blog/2018-05-25-installing-rjava-on-windows-10/installing-rjava-on-windows-10/">Windows</a>; <a href="https://www.r-bloggers.com/2018/02/installing-rjava-on-ubuntu/">Ubuntu</a>). This package is not well supported and rdkit is preferred.)</p>
<p>The following sections provide more detailed information on how to use the tools provided to interact with the database and customize it for other uses or go directly to the “Using DIMSpec” section and continue using the project.</p>
<p><strong>[OPTIONAL]</strong> It is helpful to have some data on hand to populate and evaluate the database. Every effort has been made to simplify the process of building databases using this tool, and data can be populated from CSV files of a defined structure; examples are provided but the process of generating them can be somewhat onerous as key relationships must be defined to automatically populate in this manner. Future work may be able to simplify this process further, if necessary, but for now, interested researchers within 646 are encouraged to contact this ROA’s authors for guidance on how to transform data to fit this schema.</p>
</div>
<div id="quick-start-guide" class="section level3 unnumbered hasAnchor">
<h3>Quick Start Guide<a href="instructions.html#quick-start-guide" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This section provides instructions in a “quick start” format. While every effort has been made when building the underlying functionality to make this as painless as possible, success may vary from system to system. This assumes that R v4.1 or later is installed.</p>
<ul>
<li><em>If using RStudio:</em>
<ol style="list-style-type: decimal">
<li>Download the project and open it in RStudio.</li>
<li>Open the file at “R/compliance.R” in the editor.</li>
<li>Click the “Source” button at the top right of the editor pane.</li>
</ol></li>
<li><em>If not using RStudio:</em>
<ol style="list-style-type: decimal">
<li>Open an R session in the project directory or launch R and set your working directory to that of the project (e.g. <code>setwd(file.path("path", "to", "dimspec_dir")</code>).</li>
<li>Execute the command <code>source("R/compliance.R")</code>.</li>
</ol></li>
</ul>
<p>Using either method should in most cases establish the compute environment, including logging and argument validation, binding to a python environment providing rdkit support, launching an API server, and listing out the shiny apps available. The project is distributed with a database populated with high resolution mass spectrometry data for per- and polyfluoroalkyl substances (PFAS) for evaluation purposes both to distribute this data set and to to evaluate capabilities for reuse in other projects.</p>
</div>
</div>
<div id="project-directory" class="section level2 unnumbered hasAnchor">
<h2>Project Directory<a href="instructions.html#project-directory" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The project directory contains the following directories of interest:</p>
<ul>
<li><p><code>/config</code> Files pertaining to the build, description, and population of the underlying database, as well as certain compute environment settings and import settings. This serves for rapid rebuilding and reuse of the underlying database structure. Also included are environment establishment files for the project (“env_glob.txt”), the R session (“env_R.R”) and the optional logging (“env_logger.R”) functionality.</p>
<ul>
<li><p><code>/sql_nodes</code> Files containing the sql scripts defining the database schema, as run by the “build.sql” script. Files are separated into database “nodes” with the hope that many can be repurposed or used a la carte in future projects. A graphical representation of the database schema, the entity-relationship diagram (ERD) is also available.</p></li>
<li><p><code>/data</code> Comma-separated-value (CSV) files which can be used to populate tables defined by their SQL nodes and which will be populated according to the chosen population script. This directory contains common data which should be applicable to all database produced by this tool (i.e. normalization tables, elements and isotopes, etc.) and subdirectories containing project-specific CSV files.</p></li>
</ul></li>
<li><p><code>/example</code> Files providing examples of (mainly) import files in JavaScript Object Notation (JSON) format. These are the files used to populate empirical data and were produced by the <a href="https://github.com/usnistgov/NISTPFAS/tree/main/methodreportingtool&#39;">NIST Non-Targeted Analysis Method Reporting Tool</a>.</p></li>
<li><p><code>/images</code> If molecular models are produced by rdkit, they will be housed here, named by the molecule’s known structure identifier (e.g. SMILES, InChI, etc.). Other images may be produced during routine work and should also be placed in this directory, though user-produced images and graphics can be saved anywhere.</p></li>
<li><p><code>/inst</code> Files for rdkit integration (/rdkit), the API service (/plumber), and applications like this one (/apps).</p>
<ul>
<li><p><code>/rdkit</code> Environment establishment and rdkit functions are located here. These will determine how R connects to the python environment to integrate rdkit into an R session as well as the files necessary to build the environment (e.g. “environment.yml”). Functions in the “py_setup.R” file should suffice for most use cases.</p></li>
<li><p><code>/plumber</code> Environment establishment and API definition functions are located here. These will determine how requests to the API are routed and functionality are provided through http protocols in a RESTful manner. It comes complete with Swagger documentation available when the server is running.</p></li>
<li><p><code>/apps</code> Environment establishment, general resources, and shiny application files are located here. Each application is contained within its own directory.</p></li>
</ul></li>
<li><p><code>/logs</code> If logging functionality is turned on, logs will be written here according to the namespace of the log (e.g. “logs/log_db.txt”). /R Most files providing functionality for the project reside in the</p></li>
<li><p><code>/R</code> directory; most general R functions are housed here or in one of the subdirectories.</p></li>
</ul>
</div>
<div id="project-set-up" class="section level2 unnumbered hasAnchor">
<h2>Project Set Up<a href="instructions.html#project-set-up" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Running the compliance script using source(“R/compliance.R”) from the R console will establish the project for you in most cases. It leverages several files to determine project settings; these are detailed here for clarity and customization options, with further details provided in the <a href="technical-details.html#compute-environments">Compute Environments</a> section. To accept the default settings, source the compliance file and move on to the <a href="instructions.html#using-dimspec">Using DIMSpec</a> section(. This may take a while to resolve package dependencies. To customize your implementation, read on.</p>
<div id="step-1---global-compute-environment-settings" class="section level3 unnumbered hasAnchor">
<h3>Step 1 - Global compute environment settings<a href="instructions.html#step-1---global-compute-environment-settings" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Several options are available to customize application to any given project; settings are in the file “/config/env_glob.txt”. These values are not set at the system level to add flexibility across operating systems; they are instead session values that are available while a session is active.</p>
<table>
<caption>Table 1: Customizing global settings in the “/config/env_glob.txt” file</caption>
<colgroup>
<col width="6%" />
<col width="3%" />
<col width="90%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Setting</strong></td>
<td><strong>Type</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr class="even">
<td>DB_TITLE</td>
<td>String</td>
<td>The title to use for this implementation.</td>
</tr>
<tr class="odd">
<td>DB_NAME</td>
<td>String</td>
<td>The name of the database to create or use. For SQLite this should be a file name.</td>
</tr>
<tr class="even">
<td>EXPLICIT_PATHS</td>
<td>Logical</td>
<td>Whether or not file names are fully qualified with their path.</td>
</tr>
<tr class="odd">
<td>DB_BUILD_FILE</td>
<td>String</td>
<td>The .sql file name of the script used to build the database (e.g. “build.sql”; see <u>Database Schema</u>).</td>
</tr>
<tr class="even">
<td>DB_BUILD_FULL</td>
<td>String</td>
<td>The .sql file name of the fallback build script that should be used if the sqlite3 command line interface (CLI) tool is not available (e.g. “build_full.sql”; see <u>Database Schema</u>).</td>
</tr>
<tr class="odd">
<td>DB_DATA</td>
<td>String</td>
<td>The .sql file name of the data population script to run when populating the database at build time (e.g. “populate_common.sql”; see <u>Populating Data</u>).</td>
</tr>
<tr class="even">
<td>SQLITE_CLI</td>
<td>String</td>
<td>The name of the terminal command to launch the sqlite shell (e.g. “sqlite3”). This must be available in your PATH.</td>
</tr>
<tr class="odd">
<td>CONDA_CLI</td>
<td>String</td>
<td>The name of the terminal command to execute ana-/miniconda commands (e.g. “conda”). This must be available in your PATH.</td>
</tr>
<tr class="even">
<td>INIT_CONNECT</td>
<td>Logical</td>
<td>Whether or not to connect to the database when starting a session by sourcing the compliance script.</td>
</tr>
<tr class="odd">
<td>LOGGING_ON</td>
<td>Logical</td>
<td>Whether or not to establish an environment to perform action logging, which will carry additional information about what the tool is doing (see <u>Logger</u>).</td>
</tr>
<tr class="even">
<td>USE_API</td>
<td>Logical</td>
<td>Whether or not to activate the plumber application programming interface (API) for this session (see <u>Plumber</u>). If this is set to TRUE, the plumber service will launch in a background process by default and return control to the console.</td>
</tr>
<tr class="odd">
<td>INFORMATICS</td>
<td>Logical</td>
<td>Whether or not to establish an environment providing informatics support, primarily with RDKit. To streamline installation of only the database and R tools, set this to FALSE.</td>
</tr>
<tr class="even">
<td>USE_RDKIT</td>
<td>Logical</td>
<td>Whether or not to use RDKit for informatics (requires python). If set to FALSE, the packages BiocManager, ChemmineR, and rcdk will be installed if not available, though support for these is not provided at this time.</td>
</tr>
<tr class="odd">
<td>USE_SHINY</td>
<td>Logical</td>
<td>Whether or not to establish an environment providing support for web applications provided as part of the project (defaults to TRUE).</td>
</tr>
<tr class="even">
<td>SHINY_BG</td>
<td>Logical</td>
<td>[PLANNED FEATURE] Whether or not to launch shiny apps as part of a background process, making them immediately available from a web browser when the compliance script is executed (defaults to FALSE).</td>
</tr>
</tbody>
</table>
</div>
<div id="step-2---customizing-r-session-settings-in-the-env_r.r-file" class="section level3 unnumbered hasAnchor">
<h3>Step 2 - Customizing R session settings in the “env_R.R” file<a href="instructions.html#step-2---customizing-r-session-settings-in-the-env_r.r-file" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>More customization options that require R are available to set up the project specifically for your application. Open the file “config/env_R.R” to customize these for your use. These values are not set at the system level to add flexibility across systems; they are instead session values that are available during use of the project, and many depend on settings from the section above, which will be applied automatically if they are not already set.</p>
<table>
<caption>Table 2: Customizing settings specific to the R environment</caption>
<colgroup>
<col width="2%" />
<col width="2%" />
<col width="94%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Setting</strong></td>
<td><strong>Type</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr class="even">
<td>DB_DATE</td>
<td>Date</td>
<td>The date the database file was last created, as determined by file properties. Override with a date value (e.g. as.Date(“2022-06-01”))</td>
</tr>
<tr class="odd">
<td>DB_RELEASE</td>
<td>String</td>
<td>The major and minor release versions for this database.</td>
</tr>
<tr class="even">
<td>DB_VERSION</td>
<td>Generated String</td>
<td>Combines the DB_RELEASE and DB_DATE (if built) values for a complete version of the database.</td>
</tr>
<tr class="odd">
<td>DB_PACKAGE</td>
<td>String</td>
<td>The name of the R package allowing connection to your database (e.g. “RSQLite” in most cases, but could be any database connection package).</td>
</tr>
<tr class="even">
<td>DB_DRIVER</td>
<td>String</td>
<td>The name of the database driver function allowing connection to your database, which must be a function available in DB_PACKAGE (e.g. “SQLite”).</td>
</tr>
<tr class="odd">
<td>DB_CLASS</td>
<td>String</td>
<td>The class of an R object resulting from a call to the function defined by DB_PACKAGE::DB_DRIVER (e.g. “SQLite”); this will be used to search for and manage connections in the session.</td>
</tr>
<tr class="even">
<td>DB_CONN_NAME</td>
<td>String</td>
<td>The name to be used for the R object database connection (e.g. “con” in most cases); this defaults to a session variable named DB_CONN which can be set independently to manage multiple connections.</td>
</tr>
<tr class="odd">
<td>DEPENDS_ON</td>
<td>String Vector</td>
<td>The list of packages required by your project. The list provided is the bare minimum required for functionality in the project as distributed. Add more to expand functionality.</td>
</tr>
<tr class="even">
<td>EXCLUSIONS</td>
<td>String Vector</td>
<td>The list of files and directories to exclude from automatic loading when the compliance script is run.</td>
</tr>
<tr class="odd">
<td>IMPORT_MAP</td>
<td>String</td>
<td>Imports the mapping file determining relationships between import files and the database structure (see <u>Importing Data</u>); change the name of the CSV file (change also the function calling it if using formats other than CSV) to point to a different map.</td>
</tr>
<tr class="even">
<td>LOGGING_ON</td>
<td>Logical</td>
<td>Whether to activate logging functionality when a session begins. This defaults to the session variable named LOGGING_ON and, if not present, to TRUE. If TRUE, adds the logger package to the dependency list.</td>
</tr>
<tr class="odd">
<td>VERIFY_ARGUMENTS</td>
<td>Logical</td>
<td>Whether or not to activate function argument verification for this project. The default of TRUE will check arguments provided to many functions for compliance with function expectations and is good for development work, but also slows down execution times. Set to FALSE to turn this off.</td>
</tr>
<tr class="even">
<td>MINIMIZE</td>
<td>Logical</td>
<td>If TRUE, turns off both LOGGING_ON and VERIFY_ARGUMENTS to speed up execution time.</td>
</tr>
<tr class="odd">
<td>USE_API</td>
<td>Logical</td>
<td>Defaults to the global setting of USE_API. If TRUE, several options are provided to customize properties of the API. Set these as appropriate for advanced use cases; the defaults will make the API available on your local system at <a href="http://127.0.0.1:8080.">http://127.0.0.1:8080.</a></td>
</tr>
<tr class="even">
<td>USE_SHINY</td>
<td>Logical</td>
<td>Defaults to the global setting of USE_SHINY. If TRUE, a list of installed shiny applications will be available to your session under the named character variable SHINY_APPS which contains absolute paths to the application directories. These are launchable (and should resolve their environment) at any time during a session from the console using shiny::runApp(SHINY_APPS[[<em>app_name</em>]]) where <em>app_name</em> is the name of a shiny app in the variable. See ROA 646.04-22-002 for an example of a shiny application named “Mass Spectral Match for Non-Targeted Analysis” that ships with this project for mass spectral matching of known compounds and fragments in a user supplied data file.</td>
</tr>
</tbody>
</table>
</div>
<div id="step-3---customizing-logger-settings-in-the-env_logger.r-file" class="section level3 unnumbered hasAnchor">
<h3>Step 3 - Customizing logger settings in the “env_logger.R” file<a href="instructions.html#step-3---customizing-logger-settings-in-the-env_logger.r-file" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To provide support information about performance and support troubleshooting, a logging utility is provided with the project. Logs are managed by namespace and generated with the function <code>log_it</code> which uses the <code>logger</code> package for additional functionality (see <a href="technical-details.html#logger">Logger</a>). Customization options for the format of these logging messages are provided, though under most circumstances should be left as-is to support reading logs back into a session. These values are not set at the system level to add flexibility across systems; they are instead session values that are available during use of the project, and many depend on settings from the sections above, which will be applied automatically if they are not already set.</p>
<p>Three support functions are also provided in this file to update the logger settings during a session (<code>update_logger_settings</code>), read logs from a file back into the session (<code>read_log</code>), and convert a log file into a session data frame for deeper inspection (<code>log_as_dataframe</code>).</p>
<p>Environment set up files that follow the same approach are also provided for rdkit integration, the plumber API server, and shiny web applications; these are not detailed here and should only be changed when necessary. See those sections in Technical Details for more information.</p>
<table>
<caption>Table 3: Customizing logger settings; generally, these should not be changed, but LOGGING is easily extended for developing different applications of DIMSpec.</caption>
<colgroup>
<col width="6%" />
<col width="6%" />
<col width="87%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Setting</strong></td>
<td><strong>Type</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr class="even">
<td>LOG_DIRECTORY</td>
<td>String Path</td>
<td>The relative path to the project directory housing logs. This defaults to the session variable named LOG_DIRECTORY and, if not present, to “logs”. If that directory is not present, it will be created.</td>
</tr>
<tr class="odd">
<td>layout_console</td>
<td>Function String</td>
<td>The format to use when printing logs to the console, by default interpreted by logger::layout_glue_generator, but could be any logger generator.</td>
</tr>
<tr class="even">
<td>layout_file</td>
<td>Function String</td>
<td>The format to use when printing logs to a file, by default interpreted by logger::layout_glue_generator, but could be any logger generator.</td>
</tr>
<tr class="odd">
<td>log_remove_color</td>
<td>Regex String</td>
<td>A regular expression describing color formatting to strip out when reading logs back into a data frame. If printing to the console in RStudio, colors will be maintained. This should coordinate with the layout_console format.</td>
</tr>
<tr class="even">
<td>log_split_column</td>
<td>Regex String</td>
<td>A regular expression describing the character formatting used to split log records into columns when reading logs back in as a data frame object with the log_as_dataframe function. This should always be coordinated with the layout_file format.</td>
</tr>
<tr class="odd">
<td>LOGGING</td>
<td>List</td>
<td><p>A nested list object defining logging settings for different namespaces. Each must include the following named settings:</p>
<ul>
<li><strong><em>log</em></strong> determines whether to log a given namespace (TRUE/FALSE);</li>
<li><strong><em>ns</em></strong> is the character scalar namespace called as part of <code>log_it</code>;</li>
<li><strong><em>to</em></strong> is the destination of the log message, one of <code>"file"</code>, <code>"console"</code>, or <code>"both"</code>;</li>
<li><strong><em>file</em></strong> is the file path to the log file which will be created if it does not exist;</li>
<li><strong><em>threshold</em></strong> determines what level at which to log messages (e.g. setting a threshold of <code>"info"</code> will not log messages at the <code>"trace"</code> level; see the logger <a href="https://daroczig.github.io/logger/articles/Intro.html">package documentation</a> for details).</li>
</ul>
<p>New namespaces can be added during the session if desired, but this list should define the most common ones. More information about the logging environment is provided in the <a href="technical-details.html#logger">Logger</a> section of Technical Details.</p></td>
</tr>
<tr class="even">
<td>LOGGING_WARNS</td>
<td>Logical</td>
<td>Whether to log all warning messages generated during this session by default.</td>
</tr>
<tr class="odd">
<td>LOGGING_ERRORS</td>
<td>Logical</td>
<td>Whether to log all error messages generated during this session by default.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="using-dimspec" class="section level2 unnumbered hasAnchor">
<h2>Using DIMSpec<a href="instructions.html#using-dimspec" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are several R packages required for this project, so initial set up may take some time. To streamline this process once set up is complete, a compliance script is available that will install and load required packages; run <code>source("R/compliance.R")</code> in the console to establish the runtime environment. See <a href="references.html#references">References</a> for the complete list of library dependencies. Based on project settings, components can be turned on or off as desired for lighter weight applications. In many cases helper functions are available to turn these components back on during an active session without interrupting the current environment. The following sections assume the compliance script has run and that all functions are available. At any time, use <code>fn_guide()</code> or <code>fn_help(fn)</code> where <em><code>fn</code></em> is the name of a function to view function documentation.</p>
<div id="database-connections" class="section level3 unnumbered hasAnchor">
<h3>Database Connections<a href="instructions.html#database-connections" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="connecting-to-an-existing-database" class="section level4 unnumbered hasAnchor">
<h4>Connecting to an Existing Database<a href="instructions.html#connecting-to-an-existing-database" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This project uses SQLite by default as a portable database engine where the database is contained to a single file. To connect a project to a particular database (e.g. you have multiple databases for different projects), simply change the value of <code>DB_NAME</code> in “env_glob.txt” prior to sourcing the compliance file. The database distributed with the project contains mass spectral data for per- and polyfluoroalkyl substances as an example. It (and any databases created using this project), opens in <a href="https://www.sqlite.org/wal.html">write-ahead logging</a> (WAL) mode for speed and concurrency. This does generally require the database file to be present on the same machine as the project but allows installation on instrument controllers that may not comply with network security restrictions. As with all SQLite databases, foreign key enforcement must be turned on when connecting with <code>pragma foreign_keys = on;</code> the <code>manage_connection</code> function takes care of this and other connection management aspects automatically and is the recommended way to connect and disconnect to DIMSpec databases. Call <code>manage_connection(reconnect = FALSE)</code> to close the connection. Calling <code>manage_connection</code> calls <code>DBI::dbConnect</code> and <code>DBI::dbDisconnect</code> with certain checks and parameter defined side effects to manage the connection.</p>
</div>
<div id="creating-a-new-database" class="section level4 unnumbered hasAnchor">
<h4>Creating a New Database<a href="instructions.html#creating-a-new-database" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Tooling to create a new SQLite database using this schema are built into the project; functions are in the “R/db_comm.R” file and help documentation is available from within the project using the <code>fn_guide</code> and <code>fn_help</code> functions. When creating a new database, prior to sourcing the compliance file, set options in the “env_glob.txt” and “env_r.R” files appropriately. If the file identified by <code>DB_NAME</code> does not exist it will be created according to the SQL scripts selected as <code>DB_BUILD_FILE</code> and <code>DB_DATA</code>; edit those files if necessary for your use case. To build a new, empty database users need only set <code>DB_NAME</code> to a file that does not exist in the project directory, and <code>DB_DATA</code> to “populate_common.sql” which contains the majority of source data necessary to populate normalization tables (see the <a href="technical-details.html#database-schema">Database Schema</a> and <a href="technical-details.html#populating-data-at-build">Populating Data</a> sections for more detail).</p>
<p>Alternatively, once the compliance file has been sourced, a new database may be created directly from R with the <code>build_db</code> function; this function takes as default values those provided in the environment, but you can at any time define different specifications. For example, to create a new database with a different SQL definition and population script use:</p>
<pre><code>  build_db(
    db = “new_database.sqlite”,
    build_from = “this_file.sql”,
    populate = TRUE,
    populate_with = “new_data.sql”,
    connect = FALSE
  )</code></pre>
<p>If a connection already exists that you wish to maintain in the session, be sure to call this with <code>connect = FALSE</code> in order to not drop the connection (see next section for managing multiple connections). If you do not wish to maintain a connection to the previous database, this can be safely called with <code>connect = TRUE</code> (the default) and the prior connection will be replaced with the new one.</p>
</div>
<div id="connecting-to-multiple-databases" class="section level4 unnumbered hasAnchor">
<h4>Connecting to Multiple Databases<a href="instructions.html#connecting-to-multiple-databases" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If your project needs to connect to multiple databases, separate connections can be made and managed within a single R session. For convenience, the supplied <code>manage_connection</code> function will apply to the database and connection object defined in the setup files (see <a href="instructions.html#project-set-up">Project Set Up</a>). Enable a second connection alongside existing connections (e.g. the one created in the previous section) with <code>manage_connection(db = “new_database.sqlite”, conn_name = “con2”)</code> . There is no limit to the number of connections that can be made in this manner, and the WAL will be flushed each time this function is called if no other connections exist.</p>
</div>
</div>
<div id="using-a-database-connection-in-an-r-session" class="section level3 unnumbered hasAnchor">
<h3>Using a Database Connection in an R Session<a href="instructions.html#using-a-database-connection-in-an-r-session" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If <code>INIT_CONNECT = TRUE</code>, sourcing the compliance file will establish a connection to the database named in <code>DB_NAME</code> and make the connection available as an R session object with the name defined by <code>DB_CONN_NAME</code> (the default is “con”). Several convenience functions are available with those options set.</p>
<p>Functions from the <a href="https://dplyr.tidyverse.org/"><code>dplyr</code></a> package support database operations as implemented in the <a href="https://dbplyr.tidyverse.org/"><code>dbplyr</code></a> package, meaning you can work with database objects using the “tidyverse” as if they were local objects (e.g. <code>tbl(src = con, “contributors”)</code> where <code>con</code> is your database connection object and <code>“contributors”</code> is the name of a database table or view). Simple database operations (e.g. filters, joins, column selection, etc) are supported and the resulting object is an external pointer to a lazy database query; to pull data as a data frame (e.g. necessary to join a local data frame with a database query result) use <code>collect()</code> on the tbl object. There are, however, some tasks (e.g. complicated or programmatic queries) where that may prove insufficient. In that case, two options are available.</p>
<p>The connection object fully supports direct communication for SQL queries through the <a href="https://dbi.r-dbi.org/"><code>DBI</code></a> package and is likely a familiar option for users comfortable with SQL. To continue the example, <code>dbGetQuery(con, “select * from contributors”)</code> will return the same data as in the tbl example above, except that it returns a data frame rather than a pointer object.</p>
<p>For users less familiar with SQL, a custom function is provided to support nearly all database operations. There may be edge cases where it fails. Results from the following function are equivalent to the <code>dbGetQuery</code> result but will construct the query programmatically, allowing for the passing of arguments and always returning a data frame:</p>
<pre><code>  build_db_action(
    action = “select”,
    table_name = “contributors”
  )</code></pre>
<p>As this function performs argument verification and SQL interpolation to protect queries from unintended side effects, this is the recommended manner to directly interact with the database for anything other than basic queries. It supports typical database actions (including <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, and <code>DELETE</code>, as well as a custom <code>GET_ID</code> action that returns an integer vector of the <code>id</code> column for all records matching the query) and operations (<code>GROUP BY</code>, <code>ORDER BY</code>, <code>DISTINCT</code>, <code>LIMIT</code>). Search and filter options can be passed programmatically as a list and are parsed by the <code>match_criteria</code> function.</p>
<p>Queries do not have to be executed; set the argument <code>execute = FALSE</code> to examine queries prior to execution or save common queries for reuse. See the full function reference with for advanced use of the <code>build_db_action</code> and <code>match_criteria</code> functions with <code>fn_help(fn)</code>.</p>
</div>
<div id="inspecting-database-properties" class="section level3 unnumbered hasAnchor">
<h3>Inspecting Database Properties<a href="instructions.html#inspecting-database-properties" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Code decoration conventions used in the SQL files enable reading table definitions and properties from SQLite into R with the function <code>pragma_table_info.</code> Supply the name of a database table or view to get information about that table; different connections can also be used for comparison if desired. This is the interactive version; a version in JSON format can be saved using <code>save_data_dictionary.</code> This saved file is loaded during the compliance script as object <code>db_dict</code> which is a named list of data frames; names correspond to database entities. This can be regenerated and brought back into the R session at any time (see <code>data_dictionary</code>) and should be updated if modifications are made to the underlying schema.</p>
<hr />
<div class="figure">
<img src="assets/fig02-01a_data_dict1.png" title="Figure 1a. An example of the data dictionary object." id="fig02-01a" width="500" alt="" />
<p class="caption">Figure 1a. An example of the data dictionary object.</p>
</div>
<hr />
<div class="figure">
<img src="assets/fig02-01b_data_dict2.png" title="Figure 1b. Details of the &#39;samples&#39; table from the data dictionary." id="fig02-01b" width="500" alt="" />
<p class="caption">Figure 1b. Details of the “samples” table from the data dictionary.</p>
</div>
<hr />
<p>Relationships between database entities can also be queried programmatically. Use the er_map function to read the same decoration convention in the SQL definitions to extract relationships. An object is created during the compliance script as db_map to make it available to your session. This results in a nested list with names corresponding to database entities, and elements describing the object name, its type, which table(s) and column(s) it references, which table(s) reference it, which table(s) it normalizes, and which view(s) use it.</p>
<hr />
<div class="figure">
<img src="assets/fig02-02a_db_map1.png" title="Figure 2a. An example of the entity map list" id="fig02-02a" width="500" alt="" />
<p class="caption">Figure 2a. An example of the R object structure of an entity map as a list.</p>
</div>
<hr />
<div class="figure">
<img src="assets/fig02-02b_db_map2.png" title="Figure 2b. Details of the &#39;samples&#39; table from the data entity map" id="fig02-02b" width="500" alt="" />
<p class="caption">Figure 2b. Details of the “samples” table from the data entity map object in <a href="instructions.html#fig02-02a">Figure 2a</a>.</p>
</div>
</div>
<div id="using-the-api" class="section level3 unnumbered hasAnchor">
<h3>Using the Application Programming Interface (API)<a href="instructions.html#using-the-api" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<hr />
<p>Application Programming Interfaces (APIs) enable software components to communicate with each other. Most modern machine communication happens through APIs. In the context of this project, an API server is launched using the <a href="https://www.rplumber.io"><code>plumber</code></a> package to reduce computational load on R sessions or shiny applications and ensure consistent results across multiple sessions. It does not have to be used (set <code>USE_API = FALSE</code> in “env_glob.txt” to turn it off) but is encouraged and is a requirement for all shiny applications that ship with this project.</p>
<p>The compliance script launches this in a background process by default at <a href="http://127.0.0.1:8080">http://localhost:8080</a>. Use <code>api_open_doc</code> to open the documentation page directly in a browser. To start the service manually from an interactive session and load the documentation immediately for exploration and testing, use <code>api_reload(background = FALSE)</code>; if it is already running in a background process and desirable to launch a second service (e.g. for testing new endpoints or changes to existing ones), set the <code>pr</code> parameter to a different name and the <code>on_port</code> parameter to an open port (it will fail if the port is already in use). Documentation is produced by <a href="https://swagger.io">Swagger</a> and is interactive, allowing for users to enter values and get both the return and the URL necessary to execute that endpoint (<a href="#fig03-03">Figure 3</a>). See the <a href="technical-details.html#plumber">Plumber</a> section in <a href="technical-details.html#technical-details">Technical Details</a> for more information. If the compliance script is run with <code>USE_API = FALSE</code> and <code>api_reload</code> is not available, it may be more intuitive to use <code>start_api</code>.</p>
<p>Endpoints for many predictable read and search interactions are available. Session variables define the connections, and communication and control functions default to those expected values for streamlining (e.g. functions like <code>api_reload</code>, <code>api_open_doc</code>, and <code>api_endpoint</code> may be called without referring explicitly to a session object or URL for the current project).</p>
<p>The main interactivity with the API from an R session or shiny application is through the <code>api_endpoint</code> function. The first argument (i.e. <code>path</code>) should always be the endpoint being requested. Additional named parameters are then passed to the API server; the same example endpoint result in <a href="#fig03-03">Figure 3</a> called from the console would be</p>
<pre><code>  api_endpoint(
    path = “compound_data”,
    compound_id = 2627,
    return_format = “data.frame”
  )</code></pre>
<p>with an example of the results in <a href="instructions.html#fig02-04">Figure 4</a>. Endpoints of most use to those using the service will vary according to needs and are detailed in the Plumber section in Technical Details. Call them with <code>api_endpoint(path = ??)</code> and any other arguments required by the endpoint. Paths listed here are likely of most use:</p>
<ul>
<li><strong>“_ping”</strong>, <strong>“db_active”</strong>, and <strong>“rdkit_active”</strong> indicate that the server is alive and able communicate with the database and rdkit, respectively;</li>
<li><strong>“list_tables”</strong> and <strong>“list_views”</strong> return available tables and views respectively;</li>
<li><strong>“compound_data”</strong> and <strong>“peak_data”</strong> return mass spectrometry data associated with a compound or peak and must be called with <code>compound_id</code> or <code>peak_id</code> equal to the database index of the request; in most cases these should be called with <code>return_format = "data.frame"</code>;</li>
<li><strong>“table_search”</strong> is a generic database query endpoint analog for build_db_action to construct <code>SELECT</code> queries and has the most parameters for flexibility; for more information see <code>fn_help(build_db_action)</code> for details; relevant parameters are summarized here:
<ul>
<li><p><em>table_name</em> should be the name of a single table or view;</p></li>
<li><p><em>column_names</em> determine which columns are returned;</p></li>
<li><p><em>match_criteria</em> should be a list of criteria for the search convertible between R lists and JSON as necessary; values should generally follow the convention <code>list(column_name = value)</code> and can be nested for further refinement using e.g. <code>list(column_name = list(value = search_value, exclude = TRUE))</code> for an exclusion search (see <code>fn_help(clause_where)</code> for additional details); when called via <code>api_endpoint</code> R objects can be passed programmatically;</p></li>
<li><p><em>and_or</em> should be either “AND” or “OR” and determines whether multiple elements of match_criteria should be combined in an AND or OR context (e.g. whether <code>list(column1 = 1, column2 = 2)</code> should match both or either condition);</p></li>
<li><p><em>limit</em> is exactly as in the SQL context; leave as NULL to return all results or provide a value coercible to an integer to give only that many results;</p></li>
<li><p><em>distinct</em> is exactly as in the SQL context and should be either TRUE or FALSE;</p></li>
<li><p><em>get_all_columns</em> should be either TRUE or FALSE and will ensure the return of all columns by overriding the <code>column_names</code> parameter;</p></li>
<li><p><em>execute</em> should be either TRUE or FALSE and determines whether the constructed call results are returned (TRUE) or just the URL (FALSE); and</p></li>
<li><p><em>single_column_as_vector</em> should be either TRUE or FALSE and, if TRUE, returns an unnamed vector of results if only a single column is returned.</p></li>
</ul></li>
</ul>
<p>These and other endpoints can be easily defined, expanded, or refined as needed to meet project requirements. Use <code>api_reload</code> to refresh the server when definitions change, or test interactively prior to deployment using Swagger by launching a separate server either by opening the plumber file and clicking the “Run API” button in RStudio, or using the <code>api_start</code> or <code>api_reload</code> functions as described above. To support eventual network deployment, any number of API servers may be launched manually on predefined ports to allow for load balancing.</p>
<hr />
<div class="figure">
<img src="assets/fig02-03_swagger_example.png" title="Figure 3. Screen shot and descriptions of the interactive Swagger documentation page for the endpoint /compound_data, available using api_open_doc(). Click the &#39;Try It Out&#39; button to activate the testing mode." id="fig02-03" width="500" alt="" />
<p class="caption">Figure 3. Screen shot and descriptions of the interactive Swagger documentation page for the endpoint <code>/compound_data</code>, available using <code>api_open_doc()</code>. Click the “Try It Out” button to activate the testing mode.</p>
</div>
<hr />
<div class="figure">
<img src="assets/fig02-04_endpoint_example.png" title="Figure 4. Screen shot of the result of calling the same API endpoint as in Figure 3 from an R session" id="fig02-04" width="500" alt="" />
<p class="caption">Figure 4. Screen shot of the result of calling the same API endpoint as in Figure 3 from an R session.</p>
</div>
<hr />
</div>
<div id="using-rdkit" class="section level3 unnumbered hasAnchor">
<h3>Using rdkit<a href="instructions.html#using-rdkit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For chemometrics integration, <code>rdkit</code> is made available as part of the project. This user guide does not provide details about <code>rdkit</code>; users are instead directed to the <a href="https://www.rdkit.org/docs/index.html">documentation</a> for details. All functionality provided as part of <code>rdkit</code> is supported with some limitations through the <a href="https://rstudio.github.io/reticulate"><code>reticulate</code></a> package. In most cases the required environment should resolve during the compliance script. On certain systems it may be desirable to install the environment manually (instructions in the <a href="technical-details.html#python">Python</a> section of <a href="technical-details.html#technical-details">Technical Details</a>).</p>
<p>Once an R session has activated and bound to a python environment it cannot be deactivated, but instead must be terminated to drop this binding. Once bound to a session object, all <code>rdkit</code> functions are accessible as a list of functions (just as in any python integration using reticulate) following <code>rdkit</code> module structures (e.g. <code>rdk$Chem$MolFromSmiles("CN1C=NC2=C1C(=O)N(C(=O)N2C)C")</code>). Though these can be chained together or piped, for stability it is recommended to store the return of each call as a variable; returned objects may not always be readily used in further functions.</p>
<p>A few custom R functions are made available to assist with the process. The implementation will depend on the environment definition found in “inst/rdkit/env_py.R” but in the standard use case will result in a session object named <code>rdk</code> tied to a python environment named “nist_hrms_db” using packages built from conda forge. See the function reference guide (<code>fn_guide()</code>) for additional details, but the following functions are likely the most useful:</p>
<ul>
<li><p><code>setup_rdkit</code> is a convenience function that should install and bind to python in a session;</p></li>
<li><p><code>rdkit_active</code> is the main check to determine whether or not rdkit has been bound to the current session and allows for setting multiple bindings if desired by setting <code>rdkit_ref</code> to a different value, and will trigger <code>setup_rdkit</code> if called with <code>make_if_not = TRUE</code>;</p></li>
<li><p><code>molecule_picture</code> creates a graphic of a molecular model from structural notation and is an example of <code>rdkit</code> functionality; and</p></li>
<li><p><code>rdkit_mol_aliases</code> generates machine-readable structural notation in a variety of formats (e.g. InChI and InChIKey) given a notation with a known format and can interchange between these to create molecular aliases; all formats supported by rdkit are attempted if <code>get_aliases = NULL</code> (<a href="instructions.html#fig02-05">Figure 5</a>) but generally these would be specific by project needs; results that fail or are blank are removed and the return is by default a data frame to support any number of identifiers with one pass.</p></li>
</ul>
<hr />
<div class="figure">
<img src="assets/fig02-05_rdkit_molecular_aliases.png" title="Figure 5. All molecular aliases as seen in the RStudio viewer for results of a call to `rdkit_mol_aliases(&#39;CN1C=NC2=C1C(=O)N(C(=O)N2C)C&#39;, get_aliases = NULL)`" id="fig02-05" width="500" alt="" />
<p class="caption">Figure 5. All molecular aliases as seen in the RStudio viewer for results of a call to <code>rdkit_mol_aliases("CN1C=NC2=C1C(=O)N(C(=O)N2C)C", get_aliases = NULL)</code></p>
</div>
<hr />
</div>
<div id="logging" class="section level3 unnumbered hasAnchor">
<h3>Logging<a href="instructions.html#logging" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Logging messages for statuses, information, warnings and errors are provided throughout functions used in this project and is executed through the custom <code>log_it</code> function. This function builds on top of the <a href="https://daroczig.github.io/logger/articles/r_packages.html">logger</a> package to construct, decorate, and write to file any logging messages necessary, and offers console messages in case logger is unavailable. If logging is enabled and the <code>logger</code> package available, logs may also be written to files in the “<code>logs</code>” directory and later retrieved with the utility functions <code>read_log</code> and <code>log_as_dataframe</code>, whose first parameter is the name of the file to read from the “<code>logs</code>” directory. Logs written to disk by default are separated by namespace (e.g. “log_db.txt” vs “log_api.txt”) to facilitate support, but output files may be defined as any available .txt file path and will be appended to existing files. Logs may look odd if viewed directly as they include text decorations to display in the console.</p>
<p>Settings are available for five namespaces by default (see <a href="technical-details.html#logger">Logger</a> and <a href="instructions.html#project-set-up">Project Set Up</a> for more details) as established by the “config/env_logger.R” file; more can be enabled at any time using the <code>add_unknown_ns</code> and <code>clone_settings_from</code> parameters of <code>log_it.</code> Logs can then be generated from within any function using e.g.:</p>
<pre><code>  log_it(
    log_level = “info”,
    msg = “Log message text”,
    log_ns = “global”
  )</code></pre>
<p>where <code>log_level</code> is the category of message, <code>msg</code> is the message itself, and <code>log_ns</code> is the namespace. Settings defined in the <code>LOGGING</code> session variable determine how logs are processed. Each message produced with <code>log_it</code> includes the timestamp, namespace, status (i.e. <code>log_level</code>), function calling the message, and the message itself. While <code>log_it</code> will print to the console messages of any level, <code>log_level</code> should be one of the supported logging levels (trace, debug, info, success, warn, error, or fatal) to integrate with <code>logger</code>, which is required if the logging message is to be written to a log file.</p>
<p>Users developing on top of this infrastructure are encouraged to take advantage of the logging functionality and make liberal use of the <code>log_it</code> function to ease debugging and maintenance.</p>
<hr />
<div class="figure">
<img src="assets/fig02-06_logging_example.png" title="Figure 6. Example uses of log_it to create logging messages." id="fig02-06" width="500" alt="" />
<p class="caption">Figure 6. Example uses of <code>log_it</code> to create logging messages.</p>
</div>
<hr />
</div>
<div id="using-shiny-applications" class="section level3 unnumbered hasAnchor">
<h3>Using Shiny Applications<a href="instructions.html#using-shiny-applications" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="https://shiny.rstudio.com">Shiny</a> package enables web applications written using R, which often meaningfully make custom processing code like that written for this project available to broader audiences. Additionally, inputs can easily be type verified and restricted to preset expectations. When the compliance script is run, a named vector of available shiny apps will be available as <code>SHINY_APPS</code>. These can be started with the <code>start_app(app_name = X)</code> where <em><code>X</code></em> is the name of the application as found in <code>SHINY_APPS.</code> Shiny apps are fluid and responsive; will automatically arrange themselves to best fit your browser size and can be custom designed with any layout or functionality. By default all communication with the database is routed through the plumber API.</p>
<p>This allows environment resolution to launch applications directly from the console, without any need to run the compliance script. Launching an app is then possible directly from the console (or batch file shortcuts which could be included in later updates) using e.g.</p>
<p><code>shiny::runApp(“inst/apps/table_explorer”)</code></p>
<p>from the project directory.</p>
<p>Three shiny applications ship with this project as of the time this document was written.</p>
<ul>
<li><p><code>table_explorer</code> allows users to explore database tables and views by selecting it from a drop-down list and details definitions and connections to other tables and views; this app should be amenable to any database created with DIMSpec and is detailed in [LINK TO TABLE EXPLORER SECTION];</p></li>
<li><p><code>spectral_match</code> allows users to upload an mzML file of mass spectral data and search user-defined features of interest by mass to charge ratio and chromatographic retention time for matches in the database for both known compounds and annotated fragments, while providing contextual information about the method and samples used to generate reference spectra. The MSMatch application is detailed in [LINK TO MSMATCH SECTION].</p></li>
<li><p><code>msqc</code> allows users to perform the quality control evaluation of potential imported data and generates the necessary JSON object to be incorporated into the database. Additional information, including the workflow, will be described in a forthcoming ROA. The MSQC application is detailed in [LINK TO MSMATCH SECTION].</p></li>
</ul>
<p>An application template is also included which should accelerate development of additional applications on top of the DIMSpec infrastructure to facilitate project needs.</p>
</div>
<div id="importing-data" class="section level3 unnumbered hasAnchor">
<h3>Importing Data<a href="instructions.html#importing-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For now, data imports are only supported from the command line and those generated by the NIST Non-Targeted Analysis Method Reporting Tool (NTA MRT). That tool is a macro-enabled Microsoft Excel® workbook available on <a href="https://github.com/usnistgov/NISTPFAS/tree/main/methodreportingtool">GitHub</a> that “allows for the controlled ontology of method data reporting and the export of the data into a single concise, human-readable file, written in a standard JavaScript Object Notation (JSON).” Users fill out the workbook annotating features of interest and associated fragmentation identities. Generated method files are submitted alongside the mzML file (converted from instrumentation output using <a href="https://proteowizard.sourceforge.io/">Proteowizard’s</a> msConvert software (Adusumilli and Mallick 2017). After quality control checks are performed, the resulting JSON object holds everything necessary to import data into the database.</p>
<p>Data passing quality control checks (see the [LINK TO MSQC SECTION] section for a shiny application to check quality control aspects of mzML files) are imported using functions found primarily in the <code>“R/NIST_import_routines.R”</code> file. Field mapping is defined by the <code>“config/map_NTA_MRT.csv”</code> file, which contains a list of import file elements and their properties, with connections for each to their destination tables and columns; individual elements are resolved by the <code>map_import</code> function which does much of the transformation. New maps can be created and used in support of other import formats in the future, and as the import functions are heavily parameterized they may need to be customized.</p>
<p>The order of operations is controlled largely by the pipeline function <code>full_import</code> which is the typical use case method for importing data. That function will check that the import file(s) include requirements and recommendations as defined in <code>“config/NIST_import_requirements.json”</code> which is a JSON list of expected elements and headers within each element and whether the elements are required. When using the NTA MRT format and process to import data the default arguments to this function and the import map should not be changed, but flexibility is supported by <code>full_import</code> having a nearly exhaustive list of parameters passed to underlying functions to resolve each database node in the required order (contributors, methods, descriptions, samples, chromatography, quality control, peaks, compounds, and fragments; see <a href="technical-details.html#sql-nodes">SQL Nodes</a> in <a href="technical-details.html#technical-details">Technical Details</a> for more details about schema nodes); parameters are passed largely by name matches for underlying functions using do.call. The import process is only available from the console, provides logging (if enabled) throughout, and fully supports batch imports from a list of import files read in via <code>jsonlite::fromJSON(readr::read_file(**X**))</code> where <code>**X**</code> is a vector of file paths. Files may alternatively be imported one at a time directly from JSON files using the <code>file_name</code> parameter and leaving the <code>import_object</code> parameter as NULL. A live connection to the database is required, and when additional information is needed (e.g. to resolve or add unknown controlled table entries), users will be prompted at the command line during the process.</p>
<p>Alternatively, data can be imported when a database is built or rebuilt from comma-separated value (CSV) files. This process is not likely amenable to many projects as it requires data indices be prepopulated and accurately cross-linked across CSV files, with one CVS file for each database table being populated; this should be considered if data are already in a database-like format and can be easily cross-linked, in which case only the table and column mappings need be solved. Several such files are used to populate a “clean” database install with certain controlled vocabulary and reference tables (see files <code>“config/populate_common.sql”</code> and <code>“config/data/”</code>). Contact these authors for assistance with using the NTA MRT and msconvert process, or conversion of data into the DIMSpec schema if you feel a project’s data would be amenable to the database structure described in this document.</p>
</div>
<div id="ending-your-session" class="section level3 unnumbered hasAnchor">
<h3>Ending Your Session<a href="instructions.html#ending-your-session" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Unclosed database connections can have unintended consequences. Generally, connections to the database during a session should be managed with <code>manage_connection</code> which allows for both disconnect and reconnect (to flush the WAL and establish a new connection). The API server will need to be spun down separately using <code>stop_api.</code> Alternatively, and to preserve any data frame objects that may have been created as external pointers (i.e. as <code>dplyr tbls</code>), when users finish with their connection needs they may use the convenience function <code>close_up_shop.</code> Connections may not flush completely in all cases. If users notice the -shm and -wal files are still open in the directory, the best way to flush them is to establish a new connection and then disconnect from it, using either <code>manage_connection</code> or <code>DBI::dbConnect/DBI::dbDisconnect</code>.</p>
</div>
<div id="updating-the-schema" class="section level3 unnumbered hasAnchor">
<h3>Updating the Schema<a href="instructions.html#updating-the-schema" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At the time this ROA was written, the schema should be well defined for most use cases. Extensions can however be added at any time to suit project-specific needs. To avoid data loss, it is recommended that any table extensions be performed directly in SQL and those commands saved to an SQL script. Views can be added freely as required. If users of this database framework apply any schema extensions, the authors would be interested in learning about both the need and the implementation so it may be evaluated for inclusion in future versions.</p>
<p>This concludes the User Guide for the Database Infrastructure for Mass Spectrometry. The following section contains technical details about the implementation and user customization.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Any mention of commercial products within NIST web pages is for information only; it does not imply recommendation or endorsement by NIST.<a href="instructions.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>This release was tested on a fresh VMWare build of Ubuntu 20.04 LTS which carries several additional system requirements. Prior to running DIMSpec, install or make sure the following are available using:<code>apt install -y build-essential libcurl4-openssl-dev libxml2-dev zlib1g-dev libssl-dev libsodium-dev ffmpeg libtiff-dev libpng-dev libblas-dev liblapack-dev libarpack2-dev gfortran libcairo2-dev libx11-dev libharfbuzz-dev libfribidi-dev libudunits2-dev libgeos-dev libgdal-dev libfftw3-3 libmagick++-dev</code>After following the R <a href="https://cran.r-project.org/bin/linux/ubuntu">installation instructions for Ubuntu</a>, ensure additional requirements using:<code>apt install -y –no-install-recommends r-cran-tidyverse r-cran-shiny</code><a href="instructions.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro-start.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="technical-details.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
